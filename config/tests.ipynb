{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 34, 34])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using einops!\n",
    "import torch\n",
    "import einops\n",
    "t = torch.randn(2,4,34,34)\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 34, 34])\n",
      "torch.Size([8, 34, 34])\n"
     ]
    }
   ],
   "source": [
    "# combining dimensions\n",
    "print(einops.rearrange(t,'b c h w -> b c h w').shape)\n",
    "print(einops.rearrange(t,'b c h w -> (b c) h w').shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.7444,  0.3859],\n",
      "         [ 0.5750,  0.2586]],\n",
      "\n",
      "        [[ 2.0826,  1.0728],\n",
      "         [ 1.7080,  0.8891]]])\n",
      "*********\n",
      "tensor([[[-0.7444,  0.5750],\n",
      "         [ 0.3859,  0.2586]],\n",
      "\n",
      "        [[ 2.0826,  1.7080],\n",
      "         [ 1.0728,  0.8891]]])\n",
      "tensor(0.3859) tensor(0.3859)\n"
     ]
    }
   ],
   "source": [
    "# permuting dimensions test\n",
    "t = torch.randn(2,2,2)\n",
    "\n",
    "print(t)\n",
    "print(\"*********\")\n",
    "t2 = einops.rearrange(t,'b c d -> b d c')\n",
    "print(t2)\n",
    "\n",
    "print(t[0,0,1], t2[0,1,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[  0,   1],\n",
       "           [ 12,  13],\n",
       "           [ 24,  25],\n",
       "           [ 36,  37],\n",
       "           [ 48,  49]],\n",
       " \n",
       "          [[ 60,  61],\n",
       "           [ 72,  73],\n",
       "           [ 84,  85],\n",
       "           [ 96,  97],\n",
       "           [108, 109]],\n",
       " \n",
       "          [[120, 121],\n",
       "           [132, 133],\n",
       "           [144, 145],\n",
       "           [156, 157],\n",
       "           [168, 169]]],\n",
       " \n",
       " \n",
       "         [[[  2,   3],\n",
       "           [ 14,  15],\n",
       "           [ 26,  27],\n",
       "           [ 38,  39],\n",
       "           [ 50,  51]],\n",
       " \n",
       "          [[ 62,  63],\n",
       "           [ 74,  75],\n",
       "           [ 86,  87],\n",
       "           [ 98,  99],\n",
       "           [110, 111]],\n",
       " \n",
       "          [[122, 123],\n",
       "           [134, 135],\n",
       "           [146, 147],\n",
       "           [158, 159],\n",
       "           [170, 171]]],\n",
       " \n",
       " \n",
       "         [[[  4,   5],\n",
       "           [ 16,  17],\n",
       "           [ 28,  29],\n",
       "           [ 40,  41],\n",
       "           [ 52,  53]],\n",
       " \n",
       "          [[ 64,  65],\n",
       "           [ 76,  77],\n",
       "           [ 88,  89],\n",
       "           [100, 101],\n",
       "           [112, 113]],\n",
       " \n",
       "          [[124, 125],\n",
       "           [136, 137],\n",
       "           [148, 149],\n",
       "           [160, 161],\n",
       "           [172, 173]]],\n",
       " \n",
       " \n",
       "         [[[  6,   7],\n",
       "           [ 18,  19],\n",
       "           [ 30,  31],\n",
       "           [ 42,  43],\n",
       "           [ 54,  55]],\n",
       " \n",
       "          [[ 66,  67],\n",
       "           [ 78,  79],\n",
       "           [ 90,  91],\n",
       "           [102, 103],\n",
       "           [114, 115]],\n",
       " \n",
       "          [[126, 127],\n",
       "           [138, 139],\n",
       "           [150, 151],\n",
       "           [162, 163],\n",
       "           [174, 175]]],\n",
       " \n",
       " \n",
       "         [[[  8,   9],\n",
       "           [ 20,  21],\n",
       "           [ 32,  33],\n",
       "           [ 44,  45],\n",
       "           [ 56,  57]],\n",
       " \n",
       "          [[ 68,  69],\n",
       "           [ 80,  81],\n",
       "           [ 92,  93],\n",
       "           [104, 105],\n",
       "           [116, 117]],\n",
       " \n",
       "          [[128, 129],\n",
       "           [140, 141],\n",
       "           [152, 153],\n",
       "           [164, 165],\n",
       "           [176, 177]]],\n",
       " \n",
       " \n",
       "         [[[ 10,  11],\n",
       "           [ 22,  23],\n",
       "           [ 34,  35],\n",
       "           [ 46,  47],\n",
       "           [ 58,  59]],\n",
       " \n",
       "          [[ 70,  71],\n",
       "           [ 82,  83],\n",
       "           [ 94,  95],\n",
       "           [106, 107],\n",
       "           [118, 119]],\n",
       " \n",
       "          [[130, 131],\n",
       "           [142, 143],\n",
       "           [154, 155],\n",
       "           [166, 167],\n",
       "           [178, 179]]]]),\n",
       " torch.Size([6, 3, 5, 2]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# implementing the patch-embedding\n",
    "w = 6\n",
    "img = torch.arange(180).view(3,5,12)\n",
    "\n",
    "# Goal: rearange: B,C,H,W -> B,H*W*C\n",
    "# so dividing dims into nh and nw\n",
    "img = einops.rearrange(img,'b c (w h) -> w b c h',\n",
    "                       w = w)\n",
    "\n",
    "img, img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0,  4,  8],\n",
       "          [ 1,  5,  9],\n",
       "          [ 2,  6, 10],\n",
       "          [ 3,  7, 11]],\n",
       " \n",
       "         [[12, 16, 20],\n",
       "          [13, 17, 21],\n",
       "          [14, 18, 22],\n",
       "          [15, 19, 23]]]),\n",
       " torch.Size([2, 4, 3]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# implementing the patch-embedding\n",
    "patch_h = 1\n",
    "patch_w = 1\n",
    "\n",
    "ct = 2*3*2*2\n",
    "img = torch.arange(ct).view(2,3,2,2)\n",
    "\n",
    "# Goal: rearange: B,C,H,W -> B,H*W*C\n",
    "# so dividing dims into nh and nw\n",
    "img = einops.rearrange(img,'b c (nh ph) (nw pw) -> b (nh nw) (ph pw c)',\n",
    "                       ph = patch_h,\n",
    "                       pw = patch_w)\n",
    "\n",
    "img, img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.5403,  0.5403,  0.5403],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ..., -0.4161, -0.4161, -0.4161],\n",
       "        ...,\n",
       "        [-0.9056, -0.9056, -0.9056,  ..., -1.0000, -1.0000, -1.0000],\n",
       "        [-0.9056, -0.9056, -0.9056,  ..., -0.5328, -0.5328, -0.5328],\n",
       "        [-0.9056, -0.9056, -0.9056,  ...,  0.4242,  0.4242,  0.4242]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing out position embedding\n",
    "import torch\n",
    "\n",
    "def pos_emb(emb_dim,grid_dim,device):\n",
    "    grid_size_h,gride_size_w = grid_dim\n",
    "    \n",
    "    grid_h = torch.arange(grid_size_h,dtype=torch.float32)\n",
    "    grid_w = torch.arange(gride_size_w,dtype=torch.float32)\n",
    "    \n",
    "    \n",
    "    # meshgrid: we show for the entire grid, the index of\n",
    "    # the x & y choordinate for a given point.\n",
    "    grid = torch.meshgrid(grid_h,grid_w,indexing='ij')\n",
    "    \n",
    "    # stack along 0th dimension. (grow size of 0th)\n",
    "    grid = torch.stack(grid,dim=0)\n",
    "    \n",
    "    # obtaining our grid positions\n",
    "    # for each tensor, the relative positions\n",
    "    grid_h_pos = grid[0].reshape(-1)\n",
    "    grid_w_pos = grid[1].reshape(-1)\n",
    "    \n",
    "    # now, using our formula\n",
    "    # factor = 10k^(2i/d_model) for 2i + 1 cos, 2i sin\n",
    "    factor = 10000 ** (torch.arange(\n",
    "        start=0,\n",
    "        end = emb_dim // 4, # for each cos and sin\n",
    "        dtype = torch.float32,\n",
    "        device = device\n",
    "    )// (emb_dim//4)) # embedding dim for each cos/sin\n",
    "    \n",
    "    # now, we seperate the h embeddings into:\n",
    "    grid_h_emb = grid_h_pos[:,None].repeat(1,emb_dim // 4) / factor\n",
    "    grid_h_emb = torch.cat([torch.sin(grid_h_emb),torch.cos(grid_h_emb)],dim=-1)\n",
    "    \n",
    "    grid_w_emb = grid_w_pos[:,None].repeat(1,emb_dim // 4) / factor\n",
    "    grid_w_emb = torch.cat([torch.sin(grid_w_emb),torch.cos(grid_w_emb)],dim=-1)\n",
    "    \n",
    "    final_emb = torch.cat([grid_h_emb,grid_w_emb],dim = -1)\n",
    "    \n",
    "    return final_emb\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# so, dim is 4x4, 44 emb-dim\n",
    "\n",
    "pos_emb(250,[25,25],'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[  0,   4],\n",
       "           [  8,  12],\n",
       "           [ 16,  20],\n",
       "           [ 24,  28],\n",
       "           [ 32,  36]],\n",
       " \n",
       "          [[ 40,  44],\n",
       "           [ 48,  52],\n",
       "           [ 56,  60],\n",
       "           [ 64,  68],\n",
       "           [ 72,  76]],\n",
       " \n",
       "          [[ 80,  84],\n",
       "           [ 88,  92],\n",
       "           [ 96, 100],\n",
       "           [104, 108],\n",
       "           [112, 116]]],\n",
       " \n",
       " \n",
       "         [[[  1,   5],\n",
       "           [  9,  13],\n",
       "           [ 17,  21],\n",
       "           [ 25,  29],\n",
       "           [ 33,  37]],\n",
       " \n",
       "          [[ 41,  45],\n",
       "           [ 49,  53],\n",
       "           [ 57,  61],\n",
       "           [ 65,  69],\n",
       "           [ 73,  77]],\n",
       " \n",
       "          [[ 81,  85],\n",
       "           [ 89,  93],\n",
       "           [ 97, 101],\n",
       "           [105, 109],\n",
       "           [113, 117]]],\n",
       " \n",
       " \n",
       "         [[[  2,   6],\n",
       "           [ 10,  14],\n",
       "           [ 18,  22],\n",
       "           [ 26,  30],\n",
       "           [ 34,  38]],\n",
       " \n",
       "          [[ 42,  46],\n",
       "           [ 50,  54],\n",
       "           [ 58,  62],\n",
       "           [ 66,  70],\n",
       "           [ 74,  78]],\n",
       " \n",
       "          [[ 82,  86],\n",
       "           [ 90,  94],\n",
       "           [ 98, 102],\n",
       "           [106, 110],\n",
       "           [114, 118]]],\n",
       " \n",
       " \n",
       "         [[[  3,   7],\n",
       "           [ 11,  15],\n",
       "           [ 19,  23],\n",
       "           [ 27,  31],\n",
       "           [ 35,  39]],\n",
       " \n",
       "          [[ 43,  47],\n",
       "           [ 51,  55],\n",
       "           [ 59,  63],\n",
       "           [ 67,  71],\n",
       "           [ 75,  79]],\n",
       " \n",
       "          [[ 83,  87],\n",
       "           [ 91,  95],\n",
       "           [ 99, 103],\n",
       "           [107, 111],\n",
       "           [115, 119]]]]),\n",
       " tensor([[[[  0,   1],\n",
       "           [  8,   9],\n",
       "           [ 16,  17],\n",
       "           [ 24,  25],\n",
       "           [ 32,  33]],\n",
       " \n",
       "          [[ 40,  41],\n",
       "           [ 48,  49],\n",
       "           [ 56,  57],\n",
       "           [ 64,  65],\n",
       "           [ 72,  73]],\n",
       " \n",
       "          [[ 80,  81],\n",
       "           [ 88,  89],\n",
       "           [ 96,  97],\n",
       "           [104, 105],\n",
       "           [112, 113]]],\n",
       " \n",
       " \n",
       "         [[[  2,   3],\n",
       "           [ 10,  11],\n",
       "           [ 18,  19],\n",
       "           [ 26,  27],\n",
       "           [ 34,  35]],\n",
       " \n",
       "          [[ 42,  43],\n",
       "           [ 50,  51],\n",
       "           [ 58,  59],\n",
       "           [ 66,  67],\n",
       "           [ 74,  75]],\n",
       " \n",
       "          [[ 82,  83],\n",
       "           [ 90,  91],\n",
       "           [ 98,  99],\n",
       "           [106, 107],\n",
       "           [114, 115]]],\n",
       " \n",
       " \n",
       "         [[[  4,   5],\n",
       "           [ 12,  13],\n",
       "           [ 20,  21],\n",
       "           [ 28,  29],\n",
       "           [ 36,  37]],\n",
       " \n",
       "          [[ 44,  45],\n",
       "           [ 52,  53],\n",
       "           [ 60,  61],\n",
       "           [ 68,  69],\n",
       "           [ 76,  77]],\n",
       " \n",
       "          [[ 84,  85],\n",
       "           [ 92,  93],\n",
       "           [100, 101],\n",
       "           [108, 109],\n",
       "           [116, 117]]],\n",
       " \n",
       " \n",
       "         [[[  6,   7],\n",
       "           [ 14,  15],\n",
       "           [ 22,  23],\n",
       "           [ 30,  31],\n",
       "           [ 38,  39]],\n",
       " \n",
       "          [[ 46,  47],\n",
       "           [ 54,  55],\n",
       "           [ 62,  63],\n",
       "           [ 70,  71],\n",
       "           [ 78,  79]],\n",
       " \n",
       "          [[ 86,  87],\n",
       "           [ 94,  95],\n",
       "           [102, 103],\n",
       "           [110, 111],\n",
       "           [118, 119]]]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "from einops import rearrange\n",
    "\n",
    "t = torch.arange(120).view(3,5,8)\n",
    "nh = 2\n",
    "ph = 4\n",
    "\n",
    "t2= rearrange(t,'b p (nh ph) -> ph b p nh',\n",
    "          ph = ph)\n",
    "\n",
    "t3 = rearrange(t,'b p (ph nh) -> ph b p nh',\n",
    "          ph = ph)\n",
    "\n",
    "'''\n",
    "\n",
    "When permuting dimensions as such, we split\n",
    "the dimension based on the indices, and\n",
    "permute by switching location as usual\n",
    "\n",
    "'''\n",
    "\n",
    "t2, t3 # not equal, bc of order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6145, -1.1614,  2.4129,  ...,  0.7041, -0.2702, -0.5480],\n",
       "        [ 1.4022,  1.1210, -0.0133,  ..., -0.7224,  1.1330, -1.4041],\n",
       "        [-1.0911,  2.2567, -0.0419,  ...,  1.8025,  0.6399,  0.0396],\n",
       "        ...,\n",
       "        [ 1.3575,  0.2255, -0.5029,  ...,  0.0229,  1.0152, -0.6778],\n",
       "        [ 0.7340,  1.0899, -2.4978,  ..., -0.0961,  0.3418, -0.6880],\n",
       "        [-1.2445, -0.0147,  2.0132,  ..., -0.3695, -1.0155,  0.6094]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating custom layernorm\n",
    "import torch\n",
    "nin,nout = 30, 300\n",
    "n = torch.randn([nin,nout])\n",
    "\n",
    "n = (n - n.mean(dim=-1,keepdim=True)) / (n.std(dim=-1,keepdim=True) + 0)\n",
    "\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 2., 3.],\n",
       "         [1., 2., 3.],\n",
       "         [1., 2., 3.],\n",
       "         ...,\n",
       "         [1., 2., 3.],\n",
       "         [1., 2., 3.],\n",
       "         [1., 2., 3.]],\n",
       "\n",
       "        [[4., 5., 6.],\n",
       "         [4., 5., 6.],\n",
       "         [4., 5., 6.],\n",
       "         ...,\n",
       "         [4., 5., 6.],\n",
       "         [4., 5., 6.],\n",
       "         [4., 5., 6.]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Emb\n",
    "t = torch.arange(6).view(2,3)\n",
    "# P, Emb\n",
    "ones = torch.ones([2, 200,3])\n",
    "t = t.unsqueeze(1)\n",
    "\n",
    "# [2,1,3] * [2,200,3]\n",
    "t + ones"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "manimtest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
